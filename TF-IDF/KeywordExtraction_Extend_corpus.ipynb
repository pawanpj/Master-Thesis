{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Questionnaire_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['Ground_Truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = ['Nacaps_2018','WeGe_W2','StuMa2020','Studierdenensurvey2016','Absolventen_20092_Haupt','Promopanel_W4','Studienberechtigte_2008.3',\n",
    "'Wissenschaftlerbefragung2016','Promopanel_W3','Sozialerhebung20','WeGe_W3','Promopanel_W5','sid_corona','Promopanel_W2','Absolventen_2013-2','Absolventen_20092_Promotion',\n",
    "'Sozialerhebung21','Absolventen_20092_Mobilität','Sozialerhebung19','stsu8316_Methodenbericht','phd2014_MethodReport_W1-5_de','gsl2008_MethodReport_de', 'wegequanti_MethodReport_de',\n",
    "'scs2016_MethodReport_de', 'gra2009_MethodReport_de', 'ssy19_MethodReport_de', 'ssy20_MethodReport_de', 'ssy21_MethodReport_de', 'stuma2020_MethodReport_de','gra2013_MethodReport_de']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "file_list2= [\"/home/pawan/website_keywords_also_exist_within_documents/\" + elem + \".txt\" for elem in file_name]               \n",
    "GT_within_text = []\n",
    "\n",
    "for file_path in file_list2:\n",
    "    with open(file_path) as f_input:\n",
    "        GT_within_text.append(f_input.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GT_within_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase ground_truth  words(which also exist within text documents)\n",
    "GT_keywords_within_text = []\n",
    "for item in GT_within_text:\n",
    "    GT_keywords_within_text.append(item.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_not_in_text = ['promotionsformen, promotionsmotive,  monetäre erträge, nicht-monetäre erträge, wissenschaftlicher nachwuchs,promotionsabbruch, strukturierte promotion, persönlichkeit, erwerbsverläufe, promovierte',\n",
    "                            'integration, migration', \n",
    "                            'beruflicher verbleib von exmatrikulierten, studiensituation, studienabbruch, abbruchursachen',\n",
    "                            'effizienz, zeitreihen, studierendenbefragung, hochschulforschung', \n",
    "                            'hochschulforschung', \n",
    "                            'hochschulforschung',\n",
    "                            'studienberechtigte, hochschulforschung', \n",
    "                            'hochschulforschung', \n",
    "                            'hochschulforschung',\n",
    "                            'hochschulforschung',\n",
    "                            'integration, migration', \n",
    "                            'hochschulforschung', \n",
    "                            'internationale studierende, finanzielle situation, studienerfolg, erwerbstätige studierende, persönlichkeit, beeinträchtigt studierende, studierende, gesundheit, studierendenforschung, hochschulforschung',\n",
    "                            'hochschulforschung',\n",
    "                            'absolventen, hochschulforschung', \n",
    "                            'hochschulforschung', \n",
    "                            'hochschulforschung', \n",
    "                            'hochschulforschung', \n",
    "                            'hochschulforschung', \n",
    "                           'Qualifikation, Effizienz, Studiensituation, Zeitreihen, Studierendenbefragung, Hochschulforschung',\n",
    "                           '', \n",
    "                           '',\n",
    "                            'Integration',\n",
    "                           'Hochschulforschung',\n",
    "                           '',\n",
    "                           '',\n",
    "                           '',\n",
    "                           'Hochschulforschung',\n",
    "                           '',\n",
    "                           '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_not_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Valid_Ground_Truth'] = GT_keywords_within_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['GT not in text'] = ground_truth_not_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import pickle\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import nltk \n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# stemmer = SnowballStemmer(\"german\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('german')\n",
    "stop_words\n",
    "print(len(stop_words))\n",
    "stop_words.extend([\"a\",\"ab\",\"können\",\"bzw\", \"usw\",\"eu\",\"wiwi\",\"soz\", \"nah\",\"dsh\",\"and\",\"eng\",\"wahr\", \"kfz\", \"kiel\", \"öl\", \"fil\" \"sose\", \"ha\",\"wi\", \"übt\",\"wis\",\"vwl\",\"geben\", \"hhu\",\"bitte\",\"inkl\", \"läuft\", \"ggf\", \"ern\", \"te\", \"edv\", \"un\",\"ver\", \"finno\", \"etc\",\"ehe\",\"kfw\", \"maße\", \"möchten\", \"cau\", \"juni\", \"uds\", \"innen\", \"aber\",\"ach\",\"acht\",\"achte\",\"achten\",\"achter\",\"achtes\",\"ag\",\"alle\",\"fh\",\"allein\",\"allem\",\"allen\",\"aller\",\"allerdings\",\"alles\",\"allgemeinen\",\"als\",\"also\",\"am\",\"an\",\"andere\",\"anderen\",\"andern\",\"anders\",\"au\",\"auch\",\"auf\",\"aus\",\"ausser\",\"außer\",\"ausserdem\",\"außerdem\",\"b\",\"bald\",\"bei\",\"beide\",\"beiden\",\"beim\",\"beispiel\",\"bekannt\",\"bereits\",\"besonders\",\"besser\",\"üben\",\"besten\",\"bin\",\"sein\",\"können\",\"bis\",\"bisher\",\"bist\",\"c\",\"d\",\"da\",\"dabei\",\"dadurch\",\"dafür\",\"dagegen\",\"daher\",\"dahin\",\"dahinter\",\"damals\",\"damit\",\"danach\",\"daneben\",\"dank\",\"dann\",\"daran\",\"darauf\",\"daraus\",\"darf\",\"darfst\",\"darin\",\"darüber\",\"darum\",\"darunter\",\"das\",\"dasein\",\"daselbst\",\"dass\",\"daß\",\"dasselbe\",\"davon\",\"davor\",\"dazu\",\"dazwischen\",\"dein\",\"deine\",\"deinem\",\"deiner\",\"dem\",\"dementsprechend\",\"demgegenüber\",\"demgemäss\",\"demgemäß\",\"demselben\",\"demzufolge\",\"den\",\"denen\",\"denn\",\"denselben\",\"saarlandes\",\"der\",\"deren\",\"derjenige\",\"derjenigen\",\"dermassen\",\"dermaßen\",\"derselbe\",\"derselben\",\"des\",\"deshalb\",\"desselben\",\"dessen\",\"deswegen\",\"d.h\",\"dich\",\"die\",\"diejenige\",\"diejenigen\",\"dies\",\"diese\",\"dieselbe\",\"dieselben\",\"diesem\",\"diesen\",\"dieser\",\"dieses\",\"dir\",\"doch\",\"dort\",\"drei\",\"drin\",\"dritte\",\"dritten\",\"dritter\",\"drittes\",\"du\",\"durch\",\"durchaus\",\"dürfen\",\"dürft\",\"durfte\",\"durften\",\"e\",\"eben\",\"ebenso\",\"ehrlich\",\"ei\",\"ei,\",\"eigen\",\"eigene\",\"eigenen\",\"eigener\",\"eigenes\",\"ein\",\"einander\",\"eine\",\"einem\",\"einen\",\"einer\",\"eines\",\"einige\",\"einigen\",\"einiger\",\"einiges\",\"einmal\",\"eins\",\"elf\",\"en\",\"ende\",\"endlich\",\"entweder\",\"er\",\"Ernst\",\"erst\",\"erste\",\"ersten\",\"erster\",\"erstes\",\"es\",\"etwa\",\"etwas\",\"euch\",\"f\",\"früher\",\"fünf\",\"fünfte\",\"fünften\",\"fünfter\",\"fünftes\",\"für\",\"g\",\"gab\",\"ganz\",\"ganze\",\"ganzen\",\"ganzer\",\"ganzes\",\"gar\",\"gedurft\",\"gegen\",\"gegenüber\",\"gehabt\",\"gehen\",\"geht\",\"gekannt\",\"gekonnt\",\"gemacht\",\"gemocht\",\"gemusst\",\"genug\",\"gerade\",\"gern\",\"gesagt\",\"geschweige\",\"gewesen\",\"gewollt\",\"geworden\",\"gibt\",\"ging\",\"gleich\",\"gott\",\"gross\",\"groß\",\"grosse\",\"große\",\"grossen\",\"großen\",\"grosser\",\"großer\",\"grosses\",\"großes\",\"gut\",\"gute\",\"guter\",\"gutes\",\"h\",\"habe\",\"haben\",\"habt\",\"hast\",\"hat\",\"hatte\",\"hätte\",\"hatten\",\"hätten\",\"heisst\",\"her\",\"heute\",\"hier\",\"hin\",\"hinter\",\"hoch\",\"i\",\"ich\",\"ihm\",\"ihn\",\"ihnen\",\"ihr\",\"ihre\",\"ihrem\",\"ihren\",\"ihrer\",\"ihres\",\"im\",\"immer\",\"in\",\"indem\",\"infolgedessen\",\"ins\",\"irgend\",\"ist\",\"j\",\"ja\",\"jahr\",\"jahre\",\"jahren\",\"je\",\"jede\",\"jedem\",\"jeden\",\"jeder\",\"jedermann\",\"jedermanns\",\"jedoch\",\"jemand\",\"jemandem\",\"jemanden\",\"jene\",\"jenem\",\"jenen\",\"jener\",\"jenes\",\"jetzt\",\"k\",\"kam\",\"kann\",\"kannst\",\"kaum\",\"kein\",\"keine\",\"keinem\",\"keinen\",\"keiner\",\"kleine\",\"kleinen\",\"kleiner\",\"kleines\",\"kommen\",\"kommt\",\"können\",\"könnt\",\"konnte\",\"könnte\",\"konnten\",\"kurz\",\"l\",\n",
    "                   \"lang\",\"lange\",\"leicht\",\"leide\",\"lieber\",\"los\",\"m\",\"inn\",\"usw \",\"dfg\",\"machen\", \"erc\",\"macht\",\"machte\",\"mag\",\"magst\",\"mahn\",\"man\",\"manche\",\"manchem\",\"manchen\",\"mancher\",\"manches\",\"mann\",\"mehr\",\"mein\",\"meine\",\"meinem\",\"meinen\",\"meiner\",\"meines\",\"mensch\",\"menschen\",\"mich\",\"mir\",\"mit\",\"mittel\",\"mochte\",\"möchte\",\"mochten\",\"düsseldorf\",\"mögen\",\"möglich\",\"mögt\",\"morgen\",\"muss\",\"muß\",\"müssen\",\"musst\",\"müsst\",\"musste\",\"mussten\",\"n\",\"na\",\"nach\",\"pogs\",\"vater\",\"mutter\",\"nachdem\",\"nahm\",\"natürlich\",\"neben\",\"nein\",\"neue\",\"neuen\",\"neun\",\"neunte\",\"neunten\",\"neunter\",\"neuntes\",\"nicht\",\"nichts\",\"nie\",\"niemand\",\"niemandem\",\"niemanden\",\"noch\",\"nun\",\"nur\",\"o\",\"ob\",\"oben\",\"oder\",\"offen\",\"oft\",\"ohne\",\"Ordnung\",\"p\",\"q\",\"r\",\"recht\",\"rechte\",\"rechten\",\"rechter\",\"rechtes\",\"richtig\",\"rund\",\"s\",\"sa\",\"sache\",\"sagt\",\"sagte\",\"sah\",\"satt\",\"schlecht\",\"Schluss\",\"schon\",\"sechs\",\"sechste\",\"sechsten\",\"sechster\",\"sechstes\",\"sehr\",\"sei\",\"seid\",\"seien\",\"sein\",\"seine\",\"seinem\",\"seinen\",\"seiner\",\"seines\",\"seit\",\"seitdem\",\"selbst\",\"sich\",\"sie\",\"sieben\",\"siebente\",\"siebenten\",\"siebenter\",\"siebentes\",\"sind\",\"so\",\"solang\",\"solche\",\"solchem\",\"solchen\",\"solcher\",\"solches\",\"soll\",\"sollen\",\"sollte\",\"sollten\",\"sondern\",\"sonst\",\"sowie\",\"später\",\"statt\",\"t\",\"tag\",\"tage\",\"tagen\",\"tat\",\"teil\",\"tel\",\"tritt\",\"trotzdem\",\"tun\",\"u\",\"über\",\"überhaupt\",\"übrigens\",\"uhr\",\"um\",\"und\",\"und?\",\"uns\",\"unser\",\"unsere\",\"unserer\",\"unter\",\"v\",\"vergangenen\",\"viel\",\"viele\",\"vielem\",\"vielen\",\"vielleicht\",\"vier\",\"vierte\",\"vierten\",\"vierter\",\"viertes\",\"vom\",\"vor\",\"w\",\"wahr?\",\"während\",\"währenddem\",\"währenddessen\",\"wann\",\"war\",\"wäre\",\"waren\",\"wart\",\"warum\",\"was\",\"wegen\",\"weil\",\"weit\",\"weiter\",\"weitere\",\"weiteren\",\"weiteres\",\"welche\",\"welchem\",\"welchen\",\"welcher\",\"welches\",\"wem\",\"wen\",\"wenig\",\"wenige\",\"weniger\",\"weniges\",\"wenigstens\",\"wenn\",\"wer\",\"werde\",\"werden\",\"werdet\",\"wessen\",\"wie\",\"wieder\",\"will\",\"willst\",\"wir\",\"wird\",\"wirklich\",\"wirst\",\"wo\",\"wohl\",\"wollen\",\"wollt\",\"wollte\",\"wollten\",\"worden\",\"wurde\",\"würde\",\"wurden\",\"würden\",\"x\",\"y\",\"z\",\"z.b\",\"zehn\",\"zehnte\",\"zehnten\",\"zehnter\",\"zehntes\",\"zeit\",\"zu\",\"zuerst\",\"zugleich\",\"zum\",\"zunächst\",\"zur\",\"zurück\",\"zusammen\",\"zwanzig\",\"zwar\",\"zwei\",\"zweite\",\"zweiten\",\"zweiter\",\"zweites\",\"zwischen\",\"zwölf\",\"euer\",\"eure\",\"hattest\",\"hattet\",\"jedes\",\"mußt\",\"müßt\",\"sollst\",\"sollt\",\"soweit\",\"weshalb\",\"wieso\",\"woher\",\"wohin\"])\n",
    "print(len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, for_embedding=False):\n",
    "    \"\"\"\n",
    "        - remove any html tags (< /br> often found)\n",
    "        - Keep only ASCII + European Chars and whitespace, no digits\n",
    "        - remove single letter chars\n",
    "        - convert all whitespaces (tabs etc.) to single wspace\n",
    "        if not for embedding (but e.g. tdf-idf):\n",
    "        - all lowercase\n",
    "        - remove stopwords, punctuation and stemm\n",
    "    \"\"\"\n",
    "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
    "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
    "    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n",
    "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n",
    "#     if for_embedding:\n",
    "        # Keep punctuation\n",
    "#         RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n",
    "#         RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n",
    "\n",
    "    text = re.sub(RE_TAGS, \" \", text)\n",
    "    text = re.sub(RE_ASCII, \" \", text)\n",
    "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
    "    text = re.sub(RE_WSPACE, \" \", text)\n",
    "\n",
    "    word_tokens = word_tokenize(text)\n",
    "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
    "\n",
    "    if for_embedding:\n",
    "        # no stemming, lowering and punctuation / stop words removal\n",
    "        words_filtered = word_tokens\n",
    "    else:\n",
    "        words_filtered = [\n",
    "            word for word in words_tokens_lower if word not in stop_words\n",
    "        ] \n",
    "\n",
    "    text_clean = \" \".join(words_filtered)\n",
    "    return text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text\"] = data[\"Text\"].map(\n",
    "    lambda x: clean_text(x, for_embedding=True) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text\"][27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text_wo_sw\"] = data[\"Text\"].map(\n",
    "    lambda x: clean_text(x, for_embedding=False) if isinstance(x, str) else x\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"clean_text_wo_sw\"][27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('de_core_news_lg')\n",
    "nlp.max_length = 1500000 #or any large value, as long as you don't run out of RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using spacy model for POS tagging\n",
    "\n",
    "Extracted_Noun=[]  # can change it to Extracted_Noun\n",
    "for i in range(len(data[\"clean_text\"])):\n",
    "    Extracted_Noun.append([])\n",
    "    doc = nlp(data[\"clean_text\"][i])\n",
    "    for t in doc:\n",
    "        tag=t.pos_\n",
    "        if tag ==\"NOUN\": # for Noun, only \"NOUN\"\n",
    "            if t.text not in Extracted_Noun:\n",
    "                Extracted_Noun[i].append((t.text, t.pos_))  #for appending to it as a tuples: constructing a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracted_Noun[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatization on POS tagged text using GermaLemma\n",
    "\n",
    "from germalemma import GermaLemma\n",
    "\n",
    "lemmatizer = GermaLemma()\n",
    "\n",
    "lemmatized_words = []\n",
    "\n",
    "for i in range(len(Extracted_Noun)):  #can change it to Extracted_Noun\n",
    "    lemmatized_words.append([])\n",
    "    for j in range(len(Extracted_Noun[i])): \n",
    "            lemmatized_words[i].append(lemmatizer.find_lemma(Extracted_Noun[i][j][0], Extracted_Noun[i][j][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the list of tokens into string\n",
    "lemmatized_corpus = [' '.join(x) for x in lemmatized_words]\n",
    "print(lemmatized_corpus[27]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "wordcloud = WordCloud(width = 1000, height = 500).generate(lemmatized_corpus[0])\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding column to the dataframe\n",
    "\n",
    "data['clean_text_w_lemma']= lemmatized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text_w_lemma'][27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Lemmatization on the corpus text which contains all the stopwords.\n",
    "\n",
    "#not a good lemmatizer as the accuracy of the model for lemmatization is 73%\n",
    "\n",
    "# clean_text_w_lemma_w_sw = []  # clean text with lemmatization\n",
    "\n",
    "# for words in data[\"clean_text\"]:\n",
    "#      doc = nlp(words)\n",
    "#      result = ' '.join([token.lemma_ for token in doc]) \n",
    "#      clean_text_w_lemma_w_sw.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = (data['clean_text']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_wo_sw = (data['clean_text_wo_sw']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_w_lemma= data['clean_text_w_lemma'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df =data[\"clean_text_wo_sw\"].str.split(expand=True).stack().value_counts().reset_index()\n",
    " \n",
    "new_df.columns = ['Word', 'Frequency'] \n",
    " \n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import hist\n",
    "\n",
    "hist(new_df[0:5].Word, weights=new_df[0:5].Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Document Frequency\n",
    "\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "DF = {}\n",
    "for i in range(len(data['clean_text_w_lemma'])):\n",
    "    tokens = nltk.word_tokenize(data['clean_text_w_lemma'][i]) #without nltk.word_tokenize, it gives character level DF\n",
    "    for w in tokens:\n",
    "            try:\n",
    "                DF[w].add(i)\n",
    "            except:\n",
    "                DF[w] = {i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#way of thresholding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DF) #Total Unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[\"Documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word,freq in DF.items():\n",
    "    print(word,len(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=[]\n",
    "for word,freq in DF.items():\n",
    "    df_list.append(tuple((word,len(freq)/30)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list.sort(key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = [x[1] for x in df_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "df_analysis = pd.DataFrame.from_dict(Counter(check), orient='index').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plot\n",
    "# Draw a vertical bar chart\n",
    "\n",
    "df_analysis.plot.bar(x=\"index\", y=0, rot=65, title=\"Document Frequency Chart\");\n",
    "\n",
    "plot.show(block=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_data_w_lemma[28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_set = sample_data_w_lemma[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "cv=CountVectorizer(stop_words=stop_words,ngram_range=(1,1), min_df = 0.033)#0.05263) # trying different things\n",
    "\n",
    "word_count_vector=cv.fit_transform(sample_data_w_lemma) #training  ,  #model.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the numbers are not counts, they are the position in the sparse vector.\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_vector.shape\n",
    "#We have 19 (rows) documents and 6001 unique words (columns)!\n",
    "# With stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.stop_words_ #gives you the stop words that CountVectorizer inferred from your min_df and max_df settings as well as those that were cut off during feature selection (through the use of max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "\n",
    "tfidf_transformer.fit(word_count_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names=cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_keywords(vectorizer, feature_names, doc):\n",
    "    \"\"\"Return top k keywords from a doc using TF-IDF method\"\"\"\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector = vectorizer.transform(cv.transform([doc]))\n",
    "    \n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only TOP_K_KEYWORDS\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,200)\n",
    "    \n",
    "    return (keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for doc in sample_data_w_lemma:\n",
    "    df = {}\n",
    "    df['Text'] = doc\n",
    "    df['top_keywords'] = get_keywords(tfidf_transformer, feature_names, doc)\n",
    "    result.append(df)\n",
    "    \n",
    "final = pd.DataFrame(result)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final['top_keywords'][27]) # document 8 have 189 keywords(<topk(200)) and document 14 have 187 keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['top_keywords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for uniqueness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Calculating Document Frequency\n",
    "\n",
    "# from collections import defaultdict\n",
    "# import math\n",
    "\n",
    "# DF2 = {}\n",
    "# for i in range(len(final)):\n",
    "#     for elem in list((final['top_keywords'])[i].keys()):\n",
    "#         tokens = nltk.word_tokenize(elem) #without nltk.word_tokenize, it gives character level DF\n",
    "#         for w in tokens:\n",
    "#             try:\n",
    "#                 DF2[w].add(i)\n",
    "#             except:\n",
    "#                 DF2[w] = {i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(DF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word,freq in DF2.items():\n",
    "#     print(word,len(freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list1=[]\n",
    "# for word,freq in DF2.items():\n",
    "#     df_list1.append(tuple((word,len(freq)/19)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for uniquenees we can take the amount(count/Frequency) of documents that a keyword occurs in and then dividing it by the total amount of documents.(Document frequency)\n",
    "\n",
    "# something that comes in 19 out of 19 questionnaire, we can be sure that it is not unique and something that comes in 1 out of 19 it’s very unique.\n",
    "\n",
    "# we can define a threshold on document frquency and based on that can define the uniqueness/decisiveness of keyword\n",
    "# for i in range(len(final)):\n",
    "#     for elem in list((final['top_keywords'])[i].keys()):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(final['top_keywords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Ground_Truth']= data['Ground_Truth'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final['Valid_Ground_Truth']= data ['Valid_Ground_Truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final.to_csv(\"keywords_After_POS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=[]\n",
    "chunk_size = 1 #coz max ground truth size is 20\n",
    "for i in range(len(final['top_keywords'])):\n",
    "    predicted.append([])           #used for nested list\n",
    "    for j in range(1,int(200/chunk_size)+1):\n",
    "        predicted[i].append(list(final['top_keywords'][i].keys())[0:j*chunk_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted[0])   #predicted[0][-1] shows all the keywords in document 0, that is 200 keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data['Ground_Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Ground_Truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_for_top_15 = list(final['Ground_Truth']) #it will append the ground truth for top 15 documents so length of ground truth documents here is 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(gt_for_top_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth =[]\n",
    "for i in range(len(gt_for_top_15)):\n",
    "    ground_truth.append([gt_for_top_15[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ground_truth)):\n",
    "    ground_truth[i]= ground_truth[i][0].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ground_truth)):\n",
    "    for j in range(len(ground_truth[i])):\n",
    "        ground_truth[i][j] = ground_truth[i][j].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['top_keywords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(final['top_keywords']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# function to evaluate success of keyword extraction #\n",
    "######################################################\n",
    "def evaluate_keywords(proposed,groundtruth):\n",
    "  \"\"\"\n",
    "  Returns precision, recall, and f1 score for proposed keywords against ground truth\n",
    "  \"\"\"\n",
    "  proposed_set = set(proposed)\n",
    "  true_set = set(groundtruth)\n",
    "  \n",
    "  true_positives = len(proposed_set.intersection(true_set))\n",
    "  if len(proposed_set)==0:\n",
    "    precision = 0\n",
    "  else:\n",
    "    # note denominator reflects total number of words\n",
    "    # not total number of unique words\n",
    "    precision = true_positives/float(len(proposed)) \n",
    "      \n",
    "  if len(true_set)==0:\n",
    "    recall = 0\n",
    "  else:\n",
    "    recall = true_positives/float(len(true_set))\n",
    "  \n",
    "  if precision + recall > 0:\n",
    "    f1 = 2*precision*recall/float(precision + recall)\n",
    "  else:\n",
    "    f1 = 0\n",
    "\n",
    "  return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values = []\n",
    "for i in range(len(predicted)):\n",
    "    metric_values.append([]) \n",
    "    for j in range(len(predicted[i])):\n",
    "        metric_values[i].append(evaluate_keywords(predicted[i][j], ground_truth[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metric_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precison_values = []\n",
    "\n",
    "for i in range(len(metric_values)):\n",
    "    precison_values.append([])\n",
    "    for a_tuple in metric_values[i]:\n",
    "        precison_values[i].append(a_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(precison_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precison_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_values = []\n",
    "for i in range(len(metric_values)):\n",
    "    recall_values.append([])\n",
    "    for a_tuple in metric_values[i]:\n",
    "        recall_values[i].append(a_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score = []\n",
    "for i in range(len(metric_values)):\n",
    "    f1_score.append([])\n",
    "    for a_tuple in metric_values[i]:\n",
    "        f1_score[i].append(a_tuple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "for i in range(len(precison_values)):\n",
    "        print(\"Graph for document \"+ str(i))\n",
    "    \n",
    "        # Create some mock data\n",
    "        t = [x for x in range(1,201)]\n",
    "        data1 = precison_values[i]\n",
    "        data2 = recall_values[i]\n",
    "\n",
    "        fig, ax1 = plt.subplots()\n",
    "\n",
    "        color = 'tab:red'\n",
    "        ax1.set_xlabel('Threshold (k)')\n",
    "        ax1.set_ylabel('Precision', color=color)\n",
    "        ax1.plot(t, data1, color=color)\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        color = 'tab:blue'\n",
    "        ax2.set_ylabel('Recall', color=color)  # we already handled the x-label with ax1\n",
    "        ax2.plot(t, data2, color=color)\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#         plt.savefig(str(i) + 'Document.png',  dpi=200)  #to save the plots\n",
    "        plt.show()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_new = list(final['top_keywords'][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(set(check_new).intersection(ground_truth[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_new.index('gesundheit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_not_in_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ground_truth_not_in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_within_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GT_within_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " within the top 200 keywords , this scenario(considering only Noun) capture the keyword 'studiensituation', that is why we see the different trend in the graph for few documents compared to Noun+adjectives, we can also say that in our corpus(for that document) we have less number of adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(len(recall_values)):\n",
    "    print(\"Recall Score Graph for Documents \" + str(i))\n",
    "    t = [x for x in range(1,201)]\n",
    "    data = recall_values[i]\n",
    "#     fig, ax1 = plt.subplots()\n",
    "\n",
    "    color = 'tab:red'\n",
    "    plt.xlabel(\"Threshold(k)\")\n",
    "    plt.ylabel(\"Recall-Score\")\n",
    "    plt.plot(t, data, color=color)\n",
    "    plt.tick_params(axis='y', labelcolor=color)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(final['top_keywords'][0].values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every document : finding the location of best Recall values for first 15 document(top k for each doc)\n",
    "# we are working on Recall because for DZHW , Recall is important\n",
    "\n",
    "# Recall_Scores= recall_values[0:15]   #extracting Recall values of first 15 document(because we are also training on first 15 documents)\n",
    "\n",
    "best_recall_indices = []\n",
    "for i in range(len(recall_values)):\n",
    "    best_recall_indices.append(recall_values[i].index(max(recall_values[i]))) #gives location for best recall_values for each documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_recall_indices # will give us index of best recall_values for each docuemnts, for example: for document 0, at index 168 we have the best recall value(check below for that particular value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_recall_indices_element = []\n",
    "\n",
    "for i in range(len(best_recall_indices)):\n",
    "    Recall_values = recall_values[i]\n",
    "    best_recall_indices_element.append(Recall_values[best_recall_indices[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_recall_indices_element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_values[12][181]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for best Recall_score location, find tf-idf extracted keyword score(TF-IDF value) corresponding to it, extract for every document value at best location\n",
    "Recall_score_tf_idf = []\n",
    "for i in range(len(best_recall_indices)):\n",
    "    tf_idf_values = list(final['top_keywords'][i].values())\n",
    "    Recall_score_tf_idf.append(tf_idf_values[best_recall_indices[i]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recall_score_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(Recall_score_tf_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average value of  recall_score_tf_idf\n",
    "avearge_recall_score_tf_idf = sum(Recall_score_tf_idf)/len(Recall_score_tf_idf)\n",
    "print(\"The average is \", round(avearge_recall_score_tf_idf,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avearge_recall_score_tf_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mean value of  recall_score_tf_idf\n",
    "\n",
    "# avearge_f1_score_tf_idf = sum(f1_score_tf_idf)/len(f1_score_tf_idf)\n",
    "# print(\"The average is \", round(avearge_f1_score_tf_idf,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on last 4 documents  , test set\n",
    "\n",
    "test_set = sample_data_w_lemma[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # basically we are splitting .fit and .fit_transform and implementing them separaely to see the difference in our training and testing set\n",
    "# count matrix \n",
    "count_vector=cv.transform(test_set) \n",
    "# tf-idf scores \n",
    "tf_idf_vector_test = tfidf_transformer.transform(count_vector) #model.predict , same number of unique words as train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vector_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vector_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(get_keywords(tfidf_transformer, feature_names, test_set[0]).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for doc in test_set:\n",
    "    df = {}\n",
    "    df['Text'] = doc\n",
    "    df['top_keywords'] = get_keywords(tfidf_transformer, feature_names, doc)\n",
    "    result.append(df)\n",
    "    \n",
    "final2 = pd.DataFrame(result)\n",
    "final2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final2['Text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_values= final2['top_keywords'][1].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuple_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking minimum of recall to extract keywords for the unseen document\n",
    "\n",
    "Keywords_filter = []\n",
    "for key, value in tuple_values:\n",
    "    if value >= min(Recall_score_tf_idf):\n",
    "        Keywords_filter.append(key)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keywords_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Keywords_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#taking average of recall to extract keywords for the unseen document\n",
    "\n",
    "Keywords_filter1 = []\n",
    "for key, value in tuple_values:\n",
    "    if value >= avearge_recall_score_tf_idf:\n",
    "        Keywords_filter1.append(key)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keywords_filter1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_list=[]\n",
    "# for i in range(len(final)):\n",
    "#     new_list.append([])\n",
    "#     for elem in list((final['top_keywords'])[i].keys()):\n",
    "#         print(elem)                                 # will print 3800 words(200*19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping candidate keywords with thesaurus \n",
    "thesaurus_data = pd.read_csv(\"Thesaurus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thesaurus_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesaurus_list=thesaurus_data.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thesaurus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase thesaurus words\n",
    "new_thesaurus_list = []\n",
    "for sublist in thesaurus_list:\n",
    "    new_sublist = []\n",
    "    for item in sublist:\n",
    "        new_sublist.append(item.lower())\n",
    "    new_thesaurus_list.append(new_sublist) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_thesaurus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mapping keyword from tfidf with thesaurus \n",
    "\n",
    "keywords_after_bruteforce_mapping=[]\n",
    "for i in range(len(final)):\n",
    "#     print(i,flush=True)\n",
    "    keywords_after_bruteforce_mapping.append([])\n",
    "    for elem in list((final['top_keywords'])[i].keys()):\n",
    "        temp = [tuple((index1,index2))for index1,value1 in enumerate(new_thesaurus_list) for index2,value2 in enumerate(value1) if value2==elem]\n",
    "        if (len(temp))!=0:\n",
    "            for elem1 in temp:\n",
    "                if elem1[1]==0:\n",
    "                    if new_thesaurus_list[elem1[0]][1] == '9999':\n",
    "#                         print(\"a\",i)\n",
    "                        keywords_after_bruteforce_mapping[i].append(elem)\n",
    "                    else:\n",
    "                        keywords_after_bruteforce_mapping[i].append(tuple((elem,new_thesaurus_list[elem1[0]][1])))\n",
    "                        \n",
    "                elif elem1[1]==1:\n",
    "                    keywords_after_bruteforce_mapping[i].append(elem)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "keywords_after_bruteforce_mapping[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Keywords_after_mapping'] = keywords_after_bruteforce_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final['top_keywords'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final['top_keywords'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final['Keywords_after_mapping'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final['Keywords_after_mapping'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapping keyword from tfidf with thesaurus \n",
    "\n",
    "keywords_after_optimization=[]\n",
    "for i in range(len(final)):\n",
    "    keywords_after_optimization.append([])\n",
    "    for elem in list((final['top_keywords'])[i].items()):\n",
    "        temp = [tuple((index1,index2))for index1,value1 in enumerate(new_thesaurus_list) for index2,value2 in enumerate(value1) if value2==elem[0]]\n",
    "        if (len(temp))!=0:\n",
    "            for elem1 in temp:\n",
    "                if elem1[1]==0:\n",
    "                    if new_thesaurus_list[elem1[0]][1] == '9999':\n",
    "                        keywords_after_optimization[i].append((elem[0],elem[1]+1))\n",
    "                    else:\n",
    "                        keywords_after_optimization[i].append(tuple(((elem[0],elem[1]+1),(new_thesaurus_list[elem1[0]][1],1))))\n",
    "                        \n",
    "                elif elem1[1]==1:\n",
    "                    keywords_after_optimization[i].append((elem[0],elem[1]+1))\n",
    "        else:\n",
    "            keywords_after_optimization[i].append((elem[0],elem[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_after_optimization[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_after_optimization_sorted = []\n",
    "for j in range(len(keywords_after_optimization)):\n",
    "        keywords_after_optimization_sorted.append(sorted(keywords_after_optimization[j],key=lambda x:(-x[1],x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_after_optimization_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final['Ground_Truth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_new=[]\n",
    "chunk_size = 1\n",
    "for i in range(len(keywords_after_optimization_sorted)):\n",
    "    predicted_new.append([])           #used for nested list\n",
    "    for j in range(1,int(200/chunk_size)+1):\n",
    "        predicted_new[i].append([elem[0] for elem in keywords_after_optimization_sorted[i]][0:j*chunk_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(final['Ground_Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_new = list(final['Ground_Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_new =[]\n",
    "for i in range(len(gt_new)):\n",
    "    ground_truth_new.append([gt_new[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ground_truth_new)):\n",
    "    ground_truth_new[i]= ground_truth_new[i][0].split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(ground_truth_new)):\n",
    "    for j in range(len(ground_truth_new[i])):\n",
    "        ground_truth_new[i][j] = ground_truth_new[i][j].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_new[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_after_optimization_sorted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(keywords_after_optimization_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################\n",
    "# function to evaluate success of keyword extraction #\n",
    "######################################################\n",
    "def evaluate_keywords_new(proposed,groundtruth):\n",
    "  \"\"\"\n",
    "  Returns precision, recall, and f1 score for proposed keywords against ground truth\n",
    "  \"\"\"\n",
    "  proposed_set = set(proposed)\n",
    "  true_set = set(groundtruth)\n",
    "  \n",
    "  true_positives = len(proposed_set.intersection(true_set))\n",
    "  if len(proposed_set)==0:\n",
    "    precision = 0\n",
    "  else:\n",
    "    # note denominator reflects total number of words\n",
    "    # not total number of unique words\n",
    "    precision = true_positives/float(len(proposed)) \n",
    "      \n",
    "  if len(true_set)==0:\n",
    "    recall = 0\n",
    "  else:\n",
    "    recall = true_positives/float(len(true_set))\n",
    "  \n",
    "  if precision + recall > 0:\n",
    "    f1 = 2*precision*recall/float(precision + recall)\n",
    "  else:\n",
    "    f1 = 0\n",
    "\n",
    "  return (precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values_new = []\n",
    "for i in range(len(predicted_new)):\n",
    "    metric_values_new.append([]) \n",
    "    for j in range(len(predicted_new[i])):\n",
    "        metric_values_new[i].append(evaluate_keywords_new(predicted_new[i][j], ground_truth_new[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(metric_values_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precison_values_new = []\n",
    "\n",
    "for i in range(len(metric_values_new)):\n",
    "    precison_values_new.append([])\n",
    "    for a_tuple in metric_values_new[i]:\n",
    "        precison_values_new[i].append(a_tuple[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(precison_values_new[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precison_values_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_values_new = []\n",
    "for i in range(len(metric_values_new)):\n",
    "    recall_values_new.append([])\n",
    "    for a_tuple in metric_values_new[i]:\n",
    "        recall_values_new[i].append(a_tuple[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score_new = []\n",
    "for i in range(len(metric_values_new)):\n",
    "    f1_score_new.append([])\n",
    "    for a_tuple in metric_values_new[i]:\n",
    "        f1_score_new[i].append(a_tuple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "\n",
    "for i in range(len(precison_values_new)):\n",
    "        print(\"Graph for document \"+ str(i))\n",
    "    \n",
    "        # Create some mock data\n",
    "        t = [x for x in range(1,201)]\n",
    "        data1 = precison_values_new[i]\n",
    "        data2 = recall_values_new[i]\n",
    "\n",
    "        fig, ax1 = plt.subplots()\n",
    "\n",
    "        color = 'tab:red'\n",
    "        ax1.set_xlabel('Threshold (k)')\n",
    "        ax1.set_ylabel('Precision', color=color)\n",
    "        ax1.plot(t, data1, color=color)\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "        color = 'tab:blue'\n",
    "        ax2.set_ylabel('Recall', color=color)  # we already handled the x-label with ax1\n",
    "        ax2.plot(t, data2, color=color)\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "#         plt.savefig(str(i) + 'Document.png',  dpi=200)  #to save the plots\n",
    "        plt.show()\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final.to_csv(\"Questionnaire_check.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
